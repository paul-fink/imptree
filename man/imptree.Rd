% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/imptree.R
\name{imptree}
\alias{imptree}
\alias{imptree.formula}
\alias{imptree.default}
\alias{imptree.default}
\alias{imptree}
\title{Classification with Imprecise Probabilities}
\usage{
\method{imptree}{formula}(formula, data = NULL, weights, control,
  method = c("IDM", "NPI", "NPIapprox"), method.param, ...)

\method{imptree}{default}(x, y, ...)

imptree(x, ...)
}
\arguments{
\item{formula}{Formula describing the strucutre
(class variable ~ featutre variables).
Any interaction terms trigger an error. Must be supplied!}

\item{data}{Data.frame to evaluate supplied formula on.
If not provided the the formula is evaluated 
on the calling environment}

\item{weights}{Individual weight for the observations(Default: 1 to each)}

\item{control}{A named (partial) list according to the result of
\code{\link{imptree_control}}.}

\item{method}{Method applied for calculating the probability intervals of
the class probability. \code{"IDM"} for the Imprecise Dirichlet Model 
(Default), \code{"NPI"} for use of the Nonparametric Predictive
Inference approach and \code{"NPIapprox"} for use of the approximate 
algorithm obtaining maximal entropy of NPI generate probability intervals.}

\item{method.param}{Named list specifying the mehtod specific parameter.
See details.}

\item{\dots}{optional parameters to be passed to the main function
\code{imptree.formula} or to the call of \code{\link{imptree_control}}.}

\item{x}{A data.frame or a matrix of feature variables. The columns are required to be named.}

\item{y}{A response vector as a factor.}

\item{epistemic}{if \code{TRUE} the variables are supposed to be of epistemic nature,
if \code{FALSE} then they are ontological. See details.}
}
\value{
An object of class \code{imptree}, which is a list with the
 following components:
 \item{call}{Original call to \code{imptree}}
 \item{tree}{Object reference to the Java tree object.}
 \item{train}{Named list of training data containing the Java Object
   reference to the training data and the R model.frame}
 \item{formula}{The formula describing the data structure}
}
\description{
\code{imptree} implements Abellan and Moral's tree 
algorithm (based on Quinlans ID3) for classification. It
employes either the Imprecise Dirichlet Model (IDM) or the 
Nonparametric Predictive Inference (NPI) to generate the nodes'
class probability distribution.
}
\details{
A multi-state observation of a variable when treated epistemically, all
 the states are possible values of the observations, however in case of
 ontological interpretation each unique multi-state is assumed as a further
 single state. The a multi-state observation is characterized by a factor
 with the levels for a multi-state consisting of the unique single stated
 separated by a colon \code{":"}.
}
\references{
Abell\ifelse{latex}{\out{\'{a}}}{\ifelse{html}{\out{&aacute;}}{a}}n,
J. and Moral, S. (2005), Upper entropy of credal sets. Applications to 
credal classification, \emph{International Journal of Approximate Reasoning}
\bold{39}, 235--255.

Strobl, C. (2005), Variable Selection in Classification Trees Based on
Imprecise Probabilities, \emph{ISIPTA'05: Proceedings of the Fourth
International Symposium on Imprecise Probabilities and Their Applications},
339--348.

Baker, R. M. (2010), \emph{Multinomial Nonparametric Predictive Inference:
Selection, Classification and Subcategory Data}.
}
\seealso{
\code{\link{predict.imptree}}, \code{\link{summary.imptree}},
\code{\link{imptree_params}}, \code{\link{imptree_control}}
}
\author{
Paul Fink \email{Paul.Fink@stat.uni-muenchen.de}, based on
algorithms by J. Abell\ifelse{latex}{\out{\'{a}}}{\ifelse{html}{\out{&aacute;}}{a}}n and
S. Moral for the IDM and R. M. Baker for the NPI approach.
}
\keyword{tree}
